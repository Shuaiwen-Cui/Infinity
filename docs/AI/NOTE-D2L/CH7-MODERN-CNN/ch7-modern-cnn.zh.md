# 现代卷积神经网络

上一章我们介绍了卷积神经网络的基本原理，本章将介绍现代的卷积神经网络架构，许多现代卷积神经网络的研究都是建立在这一章的基础上的。 在本章中的每一个模型都曾一度占据主导地位，其中许多模型都是ImageNet竞赛的优胜者。ImageNet竞赛自2010年以来，一直是计算机视觉中监督学习进展的指向标。

这些模型包括：

- AlexNet。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；
- 使用重复块的网络（VGG）。它利用许多重复的神经网络块；
- 网络中的网络（NiN）。它重复使用由卷积层和$1\times 1$卷积层（用来代替全连接层）来构建深层网络;
- 含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；
- 残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；
- 稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果。

虽然深度神经网络的概念非常简单——将神经网络堆叠在一起。但由于不同的网络架构和超参数选择，这些神经网络的性能会发生很大变化。 本章介绍的神经网络是将人类直觉和相关数学见解结合后，经过大量研究试错后的结晶。 我们会按时间顺序介绍这些模型，在追寻历史的脉络的同时，帮助培养对该领域发展的直觉。这将有助于研究开发自己的架构。 例如，本章介绍的批量规范化（batch normalization）和残差网络（ResNet）为设计和训练深度神经网络提供了重要思想指导。

## 7.1. 深度卷积神经网络（AlexNet）
### 7.1.1. 学习表征
### 7.1.2. AlexNet
### 7.1.3. 读取数据集
### 7.1.4. 训练AlexNet
### 7.1.5. 小结
### 7.1.6. 练习
## 7.2. 使用块的网络（VGG）
### 7.2.1. VGG块
### 7.2.2. VGG网络
### 7.2.3. 训练模型
### 7.2.4. 小结
### 7.2.5. 练习
## 7.3. 网络中的网络（NiN）
### 7.3.1. NiN块
### 7.3.2. NiN模型
### 7.3.3. 训练模型
### 7.3.4. 小结
### 7.3.5. 练习
## 7.4. 含并行连结的网络（GoogLeNet）
### 7.4.1. Inception块
### 7.4.2. GoogLeNet模型
### 7.4.3. 训练模型
### 7.4.4. 小结
### 7.4.5. 练习
## 7.5. 批量规范化
### 7.5.1. 训练深层网络
### 7.5.2. 批量规范化层
### 7.5.3. 从零实现
### 7.5.4. 使用批量规范化层的 LeNet
### 7.5.5. 简明实现
### 7.5.6. 争议
### 7.5.7. 小结
### 7.5.8. 练习
## 7.6. 残差网络（ResNet）
### 7.6.1. 函数类
### 7.6.2. 残差块
### 7.6.3. ResNet模型
### 7.6.4. 训练模型
### 7.6.5. 小结
### 7.6.6. 练习
## 7.7. 稠密连接网络（DenseNet）
### 7.7.1. 从ResNet到DenseNet
### 7.7.2. 稠密块体
### 7.7.3. 过渡层
### 7.7.4. DenseNet模型
### 7.7.5. 训练模型
### 7.7.6. 小结
### 7.7.7. 练习